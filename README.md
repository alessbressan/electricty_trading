# Transformer
transformer v0: 300 epochs with seq_len=25, head=4, batch_size=5
transformer v1: 15 epochs with seq_len=60, head=4, batch_size=5


